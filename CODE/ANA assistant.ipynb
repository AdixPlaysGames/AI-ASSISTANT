{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45063854",
   "metadata": {},
   "source": [
    "# A N A\n",
    "## Personal assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38509914",
   "metadata": {},
   "source": [
    "## Biblioteka narodowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d70aa9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- tkinter ----\n",
    "import tkinter as tk\n",
    "from tkinter import font, Label, Tk\n",
    "from tkinter import PhotoImage\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import threading\n",
    "import wavio\n",
    "# ---- open ai ---- \n",
    "import openai\n",
    "import json\n",
    "import winsound\n",
    "from elevenlabslib import *\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import io\n",
    "from scipy.io import wavfile\n",
    "import config\n",
    "import struct\n",
    "import wave\n",
    "# ---- ElevenLabs ----\n",
    "import elevenlabs\n",
    "import soundfile as sf\n",
    "import ctypes as ct\n",
    "# ---- Google ----\n",
    "from googlesearch import search\n",
    "import webbrowser\n",
    "import random\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# ---- API ----\n",
    "with open('apiKEYS.txt') as json_file:\n",
    "    keys_data = json.load(json_file)\n",
    "openaiKEY = keys_data[\"openaiKEY\"]\n",
    "elevenlabsKEY = keys_data[\"elevenlabsKEY\"]\n",
    "openai.api_key = openaiKEY\n",
    "elevenlabs.set_api_key(elevenlabsKEY)\n",
    "\n",
    "with open('PERSONALITIES.txt', 'r', encoding='utf-8') as file:\n",
    "    system = json.load(file)\n",
    "system = system[\"ANA\"][0]\n",
    "searcher = system[\"Searcher\"]\n",
    "textgen = system[\"TEXTGEN\"]\n",
    "textForGPT = system[\"GPT\"]\n",
    "imageGPT = system[\"GPTIMAGES\"]\n",
    "properties = system(\"PROPERTIES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a475c",
   "metadata": {},
   "source": [
    "# Description\n",
    "## This is ANA, personal AI assistant capable of doing unexceptional things, such as\n",
    "## creating images, text files, responding with natural voice and browsing the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395be216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respect her personality and have fun talking to her"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60263d5",
   "metadata": {},
   "source": [
    "# Final Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66dedb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dawno się z tobą nie słyszałem. Co tam u ciebie ciekawego?\n"
     ]
    }
   ],
   "source": [
    "# ---- Open the video file ----\n",
    "video_capture = cv2.VideoCapture(\"black_fast.mp4\")\n",
    "output_wav_path = \"output.wav\"\n",
    "voiceID = \"EXAVITQu4vr4xnSDxMaL\"\n",
    "messages = ['']\n",
    "\n",
    "################################################################\n",
    "# ---- Functions That Create Magic ----\n",
    "################################################################\n",
    "# ---- GPT4 web browser ----\n",
    "def GPT_search(query):\n",
    "    searcher = searcher\n",
    "    response = openai.ChatCompletion.create(model=\"gpt-4\", messages=[{\"role\": \"assistant\", \"content\": searcher}, \n",
    "                                                                     {\"role\": \"system\", \"content\": query}], max_tokens=4000, stop=None, temperature=0.5)\n",
    "    query = response.choices[0].message.content\n",
    "    urls = []\n",
    "    for j in search(query, tld=\"co.in\", num=8, stop=8, pause=2):\n",
    "        urls.append(j)\n",
    "    source_links = {}\n",
    "    for link in urls:\n",
    "        source = link.split(\"//\")[1].split(\"/\")[0]\n",
    "        if source not in source_links:\n",
    "            source_links[source] = []\n",
    "        source_links[source].append(link)\n",
    "    selected_links = []\n",
    "    for source, links in source_links.items():\n",
    "        selected_links.append(random.choice(links))\n",
    "    selected_links = selected_links[0:4]\n",
    "    for url in selected_links:\n",
    "        webbrowser.open(url)\n",
    "        print(url)\n",
    "    \n",
    "# ---- GPT4 text file generator ----\n",
    "def GPTtextgenerator(gpt_input):\n",
    "    text = textForGPTI\n",
    "    response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"assistant\", \"content\": gpt_input}, {\"role\": \"system\", \"content\": text}], max_tokens=1000, stop=None, temperature=0.5)\n",
    "    response = response.choices[0].message.content\n",
    "\n",
    "    file_name = \"GPT4response.txt\"\n",
    "    with open(file_name, 'w') as file:\n",
    "        file.write(response)\n",
    "    os.system(\"notepad.exe \" + file_name)\n",
    "    \n",
    "# ---- Image generator ----\n",
    "def GPT_image(prompt):\n",
    "    text = imageGPT\n",
    "    response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"assistant\", \"content\": prompt}, \n",
    "                                                                             {\"role\": \"system\", \"content\": text}], max_tokens=1000, stop=None, temperature=0.5)\n",
    "    prompt = response.choices[0].message.content\n",
    "    print(prompt)\n",
    "    response = openai.Image.create(\n",
    "        prompt = prompt, \n",
    "        n=1,\n",
    "        size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    response = requests.get(image_url)\n",
    "    image_data = BytesIO(response.content)\n",
    "    image = Image.open(image_data)\n",
    "    image.save(\"AI ig/igLotismall.png\")\n",
    "    image.show()\n",
    "################################################################\n",
    "\n",
    "\n",
    "################################################################\n",
    "# ---- The rest of the code ----\n",
    "################################################################\n",
    "\n",
    "# ---- Generate window ----\n",
    "root = tk.Tk()\n",
    "root.title(\"ANA Assistant\")\n",
    "icon = tk.PhotoImage(file=\"ANAlogo.png\")\n",
    "root.iconphoto(False, icon)\n",
    "root.configure(bg='#000000')\n",
    "\n",
    "# ---- Calculate the desired canvas size based on video dimensions ----\n",
    "frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH) - 600)\n",
    "frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT) - 800)\n",
    "canvas_width = frame_width + 300\n",
    "canvas_height = frame_height + 300\n",
    "canvas = tk.Canvas(root, width=canvas_width, height=canvas_height, bg='#000000', highlightthickness=0)\n",
    "canvas.grid(row=1, column=0, columnspan=2)\n",
    "\n",
    "# ---- Caption-related variables ----\n",
    "caption_texts = [\"#3282f5\", \"#40e3a7\", \"#f7a068\", \"#6dedea\"] # colors of the dot\n",
    "current_caption_index = 0\n",
    "\n",
    "# ---- Audio-related vaiables ----\n",
    "is_recording = False\n",
    "audio_data = []\n",
    "record_thread = None\n",
    "\n",
    "# ---- Recording functions ----\n",
    "# - Start recording\n",
    "def start_recording():\n",
    "    global is_recording, audio_data\n",
    "    is_recording = True\n",
    "    audio_data = []\n",
    "    def callback(indata, frames, time, status):\n",
    "        if status:\n",
    "            print(status, flush=True)\n",
    "        audio_data.append(indata.copy())\n",
    "    with sd.InputStream(callback=callback):\n",
    "        while is_recording:\n",
    "            sd.sleep(0)\n",
    "# - Stop recording\n",
    "def stop_recording():\n",
    "    global is_recording\n",
    "    is_recording = False\n",
    "    sd.sleep(0)\n",
    "    audio_array = np.concatenate(audio_data, axis=0)\n",
    "    sf.write(\"output.wav\", audio_array, samplerate=44100)\n",
    "    \n",
    "# ---- Process message ----\n",
    "def process_system_message(system_message):\n",
    "    colon_index = system_message.find(\":\")\n",
    "    if colon_index != -1:\n",
    "        processed_message = system_message[colon_index + 1:].strip()\n",
    "        return processed_message\n",
    "    else:\n",
    "        return system_message\n",
    "\n",
    "# ---- AI audio transcription ----\n",
    "def transcribe_audio(audio):\n",
    "    global current_caption_index\n",
    "    audio_file = open(audio, \"rb\")\n",
    "    transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "    textForGPT = transcript['text']\n",
    "# ---- Here we choose which action should we use ----\n",
    "    check_text = textForGPT.lower()\n",
    "    function = 0\n",
    "    if properties[0] in check_text:\n",
    "        textForGPT = textForGPT[0]\n",
    "        function = 1\n",
    "    elif properties[1] in check_text:\n",
    "        textForGPT = textForGPT[1]\n",
    "        function = 2\n",
    "    elif properties[2] in check_text:\n",
    "        textForGPT = textForGPT[2]\n",
    "        function = 3\n",
    "    else:\n",
    "        textForGPT = textForGPT\n",
    "    \n",
    "    ################################################################\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", \n",
    "        messages=[{\"role\": \"assistant\", \"content\": textForGPT}, {\"role\": \"system\", \"content\": system}], \n",
    "        max_tokens=120, \n",
    "        stop=None, \n",
    "        temperature=0.68)\n",
    "    \n",
    "    system_message = response[\"choices\"][0].message.content\n",
    "    voice = elevenlabs.Voice(\n",
    "        voice_id = voiceID,\n",
    "        settings = elevenlabs.VoiceSettings(\n",
    "            stability = 0.37,\n",
    "            similarity_boost = 0.80))\n",
    "    #system_message = process_system_message(system_message)\n",
    "    audio = elevenlabs.generate(\n",
    "        text = system_message,\n",
    "        voice = voice,\n",
    "        model='eleven_multilingual_v2')\n",
    "    audio = AudioSegment.from_file(io.BytesIO(audio), format=\"mp3\")\n",
    "    audio.export(\"output.wav\", format=\"wav\")\n",
    "    current_caption_index = 3\n",
    "    update_caption()\n",
    "    ################################################################\n",
    "    # Check what's goin' on\n",
    "    ################################################################\n",
    "    # function pass\n",
    "    if function == 1:\n",
    "        GPT_search(check_text)\n",
    "    elif function == 2:\n",
    "        GPTtextgenerator(check_text)\n",
    "    elif function == 3:\n",
    "        GPT_image(check_text)\n",
    "    print(textForGPT)\n",
    "        \n",
    "\n",
    "# ---- Play AI ----\n",
    "def play_audio():\n",
    "    winsound.PlaySound(\"output.wav\", winsound.SND_FILENAME)\n",
    "# Thread to play audio by enter key\n",
    "def enter_key_pressed(event):\n",
    "    current_caption_index = 0 \n",
    "    update_caption()\n",
    "    audio_thread = threading.Thread(target=play_audio)\n",
    "    audio_thread.start()\n",
    "    \n",
    "# ---- Interaction ----\n",
    "def space_key_pressed(event):\n",
    "    global record_thread, current_caption_index\n",
    "    if not is_recording:\n",
    "        record_thread = threading.Thread(target=start_recording)\n",
    "        record_thread.start()\n",
    "        current_caption_index = 1 \n",
    "        update_caption()\n",
    "    else:\n",
    "        stop_recording()\n",
    "        current_caption_index = 2 \n",
    "        update_caption()\n",
    "        audio_thread = threading.Thread(target=transcribe_audio, args=(\"output.wav\",))\n",
    "        audio_thread.start()\n",
    "\n",
    "# ---- Change the dot color ----\n",
    "def update_caption():\n",
    "    caption_label.config(fg=caption_texts[current_caption_index])\n",
    "    \n",
    "# ---- Add key functions to the window ---- \n",
    "root.bind(\"<space>\", space_key_pressed)\n",
    "root.bind(\"<Return>\", enter_key_pressed)\n",
    "\n",
    "# ---- Add video ----\n",
    "def update_frame():\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:  # Video has ended, reset the video capture\n",
    "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        ret, frame = video_capture.read()\n",
    "    if ret:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_height, frame_width, _ = frame.shape\n",
    "        aspect_ratio = frame_width / frame_height\n",
    "        # Ballsize changes the ballsize :)\n",
    "        ballsize = canvas_height - 400\n",
    "        new_width = int(ballsize * aspect_ratio)\n",
    "        new_height = ballsize\n",
    "        frame = cv2.resize(frame, (new_width, new_height))\n",
    "        photo = ImageTk.PhotoImage(image=Image.fromarray(frame))\n",
    "        x = (canvas_width - frame.shape[1]) // 2\n",
    "        y = (canvas_height - frame.shape[0]) // 2 + 180\n",
    "        canvas.create_image(x, y, image=photo, anchor=tk.NW)\n",
    "        canvas.photo = photo\n",
    "    canvas.after(10, update_frame)\n",
    "update_frame()\n",
    "\n",
    "# ---- Dark title bar ----\n",
    "def dark_title_bar(window):\n",
    "    window.update()\n",
    "    DWMWA_USE_IMMERSIVE_DARK_MODE = 20\n",
    "    set_window_attribute = ct.windll.dwmapi.DwmSetWindowAttribute\n",
    "    get_parent = ct.windll.user32.GetParent\n",
    "    hwnd = get_parent(window.winfo_id())\n",
    "    rendering_policy = DWMWA_USE_IMMERSIVE_DARK_MODE\n",
    "    value = 2\n",
    "    value = ct.c_int(value)\n",
    "    set_window_attribute(hwnd, rendering_policy, ct.byref(value), ct.sizeof(value))\n",
    "dark_title_bar(root)\n",
    "\n",
    "# ---- Display captions on the canvas ----\n",
    "color = caption_texts[current_caption_index]\n",
    "caption_label = tk.Label(root, text=\"\\nl\", bg='#000000', fg=color, font=('Wingdings', 18))\n",
    "caption_label.grid(row=0, column=0, columnspan=2, sticky='n')  # Placed above the canvas\n",
    "\n",
    "\n",
    "# ---- Configure row and column weights ----\n",
    "root.grid_rowconfigure(0, weight=0)  # Prevent caption from expanding\n",
    "root.grid_rowconfigure(1, weight=1)\n",
    "root.grid_columnconfigure(0, weight=1)\n",
    "root.grid_columnconfigure(1, weight=0)\n",
    "\n",
    "# ---- Start window ----\n",
    "root.mainloop()\n",
    "\n",
    "# ---- Release the video capture and close the window on exit ----\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1776c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kod autorstwa Adriana Zaręby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce4b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
